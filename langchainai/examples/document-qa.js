import 'dotenv/config';
import { ChatOpenAI } from '@langchain/openai';
import { RetrievalQAChain } from 'langchain/chains';
import { MemoryVectorStore } from 'langchain/vectorstores/memory';
import { OpenAIEmbeddings } from '@langchain/openai';
import { RecursiveCharacterTextSplitter } from 'langchain/text_splitter';
import { Document } from '@langchain/core/documents';
import { promises as fs } from 'fs';
import path from 'path';
import readline from 'readline';

const rl = readline.createInterface({
  input: process.stdin,
  output: process.stdout
});

async function documentQAExample() {
  console.log('ğŸ“š LangChain æ–‡æ¡£é—®ç­”ç¤ºä¾‹');
  console.log('ğŸ’¡ è¿™ä¸ªç¤ºä¾‹ä¼šè¯»å–æ–‡æ¡£å¹¶å›ç­”ç›¸å…³é—®é¢˜');
  console.log('â”€'.repeat(50));

  try {
    // ç¤ºä¾‹æ–‡æ¡£å†…å®¹
    const sampleDocuments = [
      {
        content: `
        LangChain æ˜¯ä¸€ä¸ªç”¨äºå¼€å‘åŸºäºè¯­è¨€æ¨¡å‹çš„åº”ç”¨ç¨‹åºçš„æ¡†æ¶ã€‚å®ƒæä¾›äº†ä»¥ä¸‹æ ¸å¿ƒæ¦‚å¿µï¼š

        1. LLMs å’Œ Chat Models: è¯­è¨€æ¨¡å‹çš„åŒ…è£…å™¨
        2. Prompt Templates: ç”¨äºæ ¼å¼åŒ–è¾“å…¥çš„æ¨¡æ¿
        3. Chains: å°†å¤šä¸ªç»„ä»¶ç»„åˆåœ¨ä¸€èµ·
        4. Agents: ä½¿ç”¨è¯­è¨€æ¨¡å‹æ¥å†³å®šé‡‡å–å“ªäº›è¡ŒåŠ¨
        5. Memory: åœ¨é“¾æˆ–ä»£ç†è°ƒç”¨ä¹‹é—´ä¿æŒçŠ¶æ€
        6. Document Loaders: ä»å„ç§æºåŠ è½½æ–‡æ¡£
        7. Text Splitters: å°†æ–‡æ¡£åˆ†å‰²æˆå—
        8. Vectorstores: å­˜å‚¨å’Œæœç´¢åµŒå…¥
        9. Retrievers: æŸ¥è¯¢æ‚¨çš„æ•°æ®
        `,
        metadata: { source: "langchain_intro.txt" }
      },
      {
        content: `
        Node.js æ˜¯ä¸€ä¸ªåŸºäº Chrome V8 JavaScript å¼•æ“çš„ JavaScript è¿è¡Œæ—¶ç¯å¢ƒã€‚
        
        ä¸»è¦ç‰¹ç‚¹ï¼š
        - äº‹ä»¶é©±åŠ¨ã€éé˜»å¡ I/O æ¨¡å‹
        - è½»é‡çº§å’Œé«˜æ•ˆ
        - æ‹¥æœ‰ä¸–ç•Œä¸Šæœ€å¤§çš„å¼€æºåº“ç”Ÿæ€ç³»ç»Ÿ npm
        - é€‚åˆæ„å»ºå¯æ‰©å±•çš„ç½‘ç»œåº”ç”¨ç¨‹åº
        
        å¸¸ç”¨æ¨¡å—ï¼š
        - HTTP: åˆ›å»º HTTP æœåŠ¡å™¨å’Œå®¢æˆ·ç«¯
        - File System (fs): æ–‡ä»¶ç³»ç»Ÿæ“ä½œ
        - Path: å¤„ç†æ–‡ä»¶è·¯å¾„
        - Express: Web åº”ç”¨æ¡†æ¶
        `,
        metadata: { source: "nodejs_intro.txt" }
      },
      {
        content: `
        äººå·¥æ™ºèƒ½ (AI) æ˜¯è®¡ç®—æœºç§‘å­¦çš„ä¸€ä¸ªåˆ†æ”¯ï¼Œæ—¨åœ¨åˆ›å»ºèƒ½å¤Ÿæ‰§è¡Œé€šå¸¸éœ€è¦äººç±»æ™ºèƒ½çš„ä»»åŠ¡çš„ç³»ç»Ÿã€‚

        AI çš„ä¸»è¦é¢†åŸŸï¼š
        1. æœºå™¨å­¦ä¹  (ML): ä½¿è®¡ç®—æœºèƒ½å¤Ÿä»æ•°æ®ä¸­å­¦ä¹ 
        2. æ·±åº¦å­¦ä¹  (DL): ä½¿ç”¨ç¥ç»ç½‘ç»œè¿›è¡Œå­¦ä¹ 
        3. è‡ªç„¶è¯­è¨€å¤„ç† (NLP): ç†è§£å’Œç”Ÿæˆäººç±»è¯­è¨€
        4. è®¡ç®—æœºè§†è§‰: ç†è§£å’Œè§£é‡Šè§†è§‰ä¿¡æ¯
        5. æœºå™¨äººæŠ€æœ¯: åˆ›å»ºèƒ½å¤Ÿåœ¨ç‰©ç†ä¸–ç•Œä¸­æ“ä½œçš„æ™ºèƒ½æœºå™¨

        ç°ä»£ AI åº”ç”¨ï¼š
        - èŠå¤©æœºå™¨äººå’Œè™šæ‹ŸåŠ©æ‰‹
        - æ¨èç³»ç»Ÿ
        - å›¾åƒè¯†åˆ«
        - è¯­éŸ³è¯†åˆ«
        - è‡ªåŠ¨é©¾é©¶æ±½è½¦
        `,
        metadata: { source: "ai_intro.txt" }
      }
    ];

    console.log('ğŸ“„ å‡†å¤‡ç¤ºä¾‹æ–‡æ¡£...');

    // åˆ›å»ºæ–‡æ¡£å¯¹è±¡
    const documents = sampleDocuments.map(doc => 
      new Document({ pageContent: doc.content, metadata: doc.metadata })
    );

    // æ–‡æœ¬åˆ†å‰²å™¨
    const textSplitter = new RecursiveCharacterTextSplitter({
      chunkSize: 500,
      chunkOverlap: 50,
    });

    // åˆ†å‰²æ–‡æ¡£
    const splitDocs = await textSplitter.splitDocuments(documents);
    console.log(`ğŸ“‘ æ–‡æ¡£å·²åˆ†å‰²ä¸º ${splitDocs.length} ä¸ªå—`);

    // åˆ›å»ºåµŒå…¥
    const embeddings = new OpenAIEmbeddings();

    // åˆ›å»ºå‘é‡å­˜å‚¨
    console.log('ğŸ” åˆ›å»ºå‘é‡å­˜å‚¨...');
    const vectorStore = await MemoryVectorStore.fromDocuments(splitDocs, embeddings);

    // åˆ›å»ºæ£€ç´¢å™¨
    const retriever = vectorStore.asRetriever({
      k: 3, // è¿”å›æœ€ç›¸å…³çš„3ä¸ªæ–‡æ¡£å—
    });

    // åˆ›å»ºèŠå¤©æ¨¡å‹
    const chatModel = new ChatOpenAI({
      modelName: "gpt-3.5-turbo",
      temperature: 0.1,
    });

    // åˆ›å»ºé—®ç­”é“¾
    const qaChain = RetrievalQAChain.fromLLM(chatModel, retriever);

    console.log('âœ… æ–‡æ¡£é—®ç­”ç³»ç»Ÿå·²å‡†å¤‡å°±ç»ªï¼');
    console.log('ğŸ’¡ æ‚¨å¯ä»¥è¯¢é—®å…³äº LangChainã€Node.js æˆ– AI çš„é—®é¢˜');
    console.log('ğŸ’¡ è¾“å…¥ "exit" é€€å‡º\n');

    // é—®ç­”å¾ªç¯
    const askQuestion = () => {
      rl.question('â“ æ‚¨çš„é—®é¢˜: ', async (question) => {
        if (question.trim().toLowerCase() === 'exit') {
          console.log('ğŸ‘‹ å†è§ï¼');
          rl.close();
          return;
        }

        if (!question.trim()) {
          console.log('âš ï¸  è¯·è¾“å…¥æœ‰æ•ˆçš„é—®é¢˜\n');
          askQuestion();
          return;
        }

        try {
          console.log('ğŸ” æœç´¢ç›¸å…³æ–‡æ¡£...');
          
          const response = await qaChain.invoke({
            query: question
          });

          console.log(`\nğŸ’¡ ç­”æ¡ˆ: ${response.text}\n`);
          
          // æ˜¾ç¤ºç›¸å…³æ–‡æ¡£æº
          const relevantDocs = await retriever.getRelevantDocuments(question);
          if (relevantDocs.length > 0) {
            console.log('ğŸ“š å‚è€ƒæ–‡æ¡£:');
            relevantDocs.forEach((doc, index) => {
              console.log(`   ${index + 1}. ${doc.metadata.source}`);
            });
            console.log('');
          }

        } catch (error) {
          console.error('âŒ é”™è¯¯:', error.message);
          console.log('ğŸ’¡ è¯·æ£€æŸ¥æ‚¨çš„ OpenAI API é…ç½®\n');
        }

        askQuestion();
      });
    };

    askQuestion();

  } catch (error) {
    console.error('âŒ åˆå§‹åŒ–å¤±è´¥:', error.message);
    console.log('ğŸ’¡ è¯·ç¡®ä¿å·²æ­£ç¡®é…ç½® .env æ–‡ä»¶ä¸­çš„ OPENAI_API_KEY');
    rl.close();
  }
}

// å¯åŠ¨æ–‡æ¡£é—®ç­”
documentQAExample();