# ğŸš€ éƒ¨ç½²æŒ‡å—

## ğŸ“‹ ç›®å½•

1. [æœ¬åœ°éƒ¨ç½²](#æœ¬åœ°éƒ¨ç½²)
2. [Docker å®¹å™¨åŒ–éƒ¨ç½²](#docker-å®¹å™¨åŒ–éƒ¨ç½²)
3. [äº‘å¹³å°éƒ¨ç½²](#äº‘å¹³å°éƒ¨ç½²)
4. [ç”Ÿäº§ç¯å¢ƒé…ç½®](#ç”Ÿäº§ç¯å¢ƒé…ç½®)
5. [ç›‘æ§å’Œæ—¥å¿—](#ç›‘æ§å’Œæ—¥å¿—)
6. [å®‰å…¨é…ç½®](#å®‰å…¨é…ç½®)
7. [æ•…éšœæ’é™¤](#æ•…éšœæ’é™¤)

---

## ğŸ  æœ¬åœ°éƒ¨ç½²

### ç¯å¢ƒè¦æ±‚
- **Node.js**: v18.0+ 
- **npm**: v8.0+
- **å†…å­˜**: è‡³å°‘ 512MB
- **å­˜å‚¨**: è‡³å°‘ 100MB å¯ç”¨ç©ºé—´

### å¿«é€Ÿéƒ¨ç½²

```bash
# 1. å…‹éš†æˆ–ä¸‹è½½é¡¹ç›®
cd langchainai

# 2. å®‰è£…ä¾èµ–
npm install --legacy-peer-deps

# 3. é…ç½®ç¯å¢ƒå˜é‡
cp .env.example .env
# ç¼–è¾‘ .env æ–‡ä»¶ï¼Œè®¾ç½® OPENAI_API_KEY

# 4. å¯åŠ¨æœåŠ¡
npm start
```

### æœåŠ¡éªŒè¯

```bash
# æ£€æŸ¥æœåŠ¡çŠ¶æ€
curl http://localhost:3001/health

# æ£€æŸ¥ MCP çŠ¶æ€
curl http://localhost:3001/mcp/status
```

---

## ğŸ³ Docker å®¹å™¨åŒ–éƒ¨ç½²

### Dockerfile

åˆ›å»º `Dockerfile`ï¼š

```dockerfile
FROM node:18-alpine

# è®¾ç½®å·¥ä½œç›®å½•
WORKDIR /app

# å¤åˆ¶ package æ–‡ä»¶
COPY package*.json ./

# å®‰è£…ä¾èµ–
RUN npm install --legacy-peer-deps --production

# å¤åˆ¶åº”ç”¨ä»£ç 
COPY . .

# æš´éœ²ç«¯å£
EXPOSE 3001 8080

# åˆ›å»ºérootç”¨æˆ·
RUN addgroup -g 1001 -S nodejs
RUN adduser -S nextjs -u 1001
USER nextjs

# å¯åŠ¨å‘½ä»¤
CMD ["npm", "start"]
```

### Docker Compose

åˆ›å»º `docker-compose.yml`ï¼š

```yaml
version: '3.8'

services:
  langchain-ai:
    build: .
    ports:
      - "3001:3001"
      - "8080:8080"
    environment:
      - NODE_ENV=production
      - PORT=3001
      - OPENAI_API_KEY=${OPENAI_API_KEY}
      - TEMPERATURE=0.7
      - MAX_TOKENS=2000
    volumes:
      - ./logs:/app/logs
      - ./data:/app/data
    restart: unless-stopped
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:3001/health"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 40s

  # å¯é€‰ï¼šæ·»åŠ  Nginx åå‘ä»£ç†
  nginx:
    image: nginx:alpine
    ports:
      - "80:80"
      - "443:443"
    volumes:
      - ./nginx.conf:/etc/nginx/nginx.conf
      - ./ssl:/etc/nginx/ssl
    depends_on:
      - langchain-ai
    restart: unless-stopped
```

### æ„å»ºå’Œè¿è¡Œ

```bash
# æ„å»ºé•œåƒ
docker build -t langchain-ai .

# ä½¿ç”¨ Docker Compose è¿è¡Œ
docker-compose up -d

# æŸ¥çœ‹æ—¥å¿—
docker-compose logs -f langchain-ai

# åœæ­¢æœåŠ¡
docker-compose down
```

---

## â˜ï¸ äº‘å¹³å°éƒ¨ç½²

### AWS éƒ¨ç½²

#### 1. EC2 éƒ¨ç½²

```bash
# å¯åŠ¨ EC2 å®ä¾‹ (Amazon Linux 2)
# t3.small æˆ–æ›´é«˜é…ç½®

# å®‰è£… Node.js
curl -o- https://raw.githubusercontent.com/nvm-sh/nvm/v0.39.0/install.sh | bash
source ~/.bashrc
nvm install 18
nvm use 18

# å®‰è£… PM2
npm install -g pm2

# éƒ¨ç½²åº”ç”¨
git clone <your-repo>
cd langchainai
npm install --legacy-peer-deps
npm run build

# ä½¿ç”¨ PM2 å¯åŠ¨
pm2 start ecosystem.config.js
pm2 save
pm2 startup
```

#### 2. ECS éƒ¨ç½²

åˆ›å»º `task-definition.json`ï¼š

```json
{
  "family": "langchain-ai",
  "taskRoleArn": "arn:aws:iam::account:role/ecsTaskRole",
  "executionRoleArn": "arn:aws:iam::account:role/ecsTaskExecutionRole",
  "networkMode": "awsvpc",
  "requiresCompatibilities": ["FARGATE"],
  "cpu": "512",
  "memory": "1024",
  "containerDefinitions": [
    {
      "name": "langchain-ai",
      "image": "your-account.dkr.ecr.region.amazonaws.com/langchain-ai:latest",
      "portMappings": [
        {
          "containerPort": 3001,
          "protocol": "tcp"
        }
      ],
      "environment": [
        {
          "name": "NODE_ENV",
          "value": "production"
        }
      ],
      "secrets": [
        {
          "name": "OPENAI_API_KEY",
          "valueFrom": "arn:aws:secretsmanager:region:account:secret:openai-key"
        }
      ],
      "logConfiguration": {
        "logDriver": "awslogs",
        "options": {
          "awslogs-group": "/ecs/langchain-ai",
          "awslogs-region": "us-east-1",
          "awslogs-stream-prefix": "ecs"
        }
      }
    }
  ]
}
```

### Google Cloud Platform

```bash
# ä½¿ç”¨ Cloud Run éƒ¨ç½²
gcloud run deploy langchain-ai \
  --image gcr.io/your-project/langchain-ai \
  --platform managed \
  --region us-central1 \
  --allow-unauthenticated \
  --port 3001 \
  --memory 1Gi \
  --cpu 1 \
  --set-env-vars NODE_ENV=production
```

### Azure å®¹å™¨å®ä¾‹

```bash
# éƒ¨ç½²åˆ° Azure Container Instances
az container create \
  --resource-group myResourceGroup \
  --name langchain-ai \
  --image your-registry/langchain-ai:latest \
  --ports 3001 8080 \
  --environment-variables NODE_ENV=production \
  --secure-environment-variables OPENAI_API_KEY=your-key \
  --cpu 1 \
  --memory 2
```

---

## ğŸ”§ ç”Ÿäº§ç¯å¢ƒé…ç½®

### PM2 é…ç½®

åˆ›å»º `ecosystem.config.js`ï¼š

```javascript
module.exports = {
  apps: [{
    name: 'langchain-ai',
    script: 'index.js',
    instances: 'max',
    exec_mode: 'cluster',
    env: {
      NODE_ENV: 'development',
      PORT: 3001
    },
    env_production: {
      NODE_ENV: 'production',
      PORT: 3001
    },
    error_file: './logs/err.log',
    out_file: './logs/out.log',
    log_file: './logs/combined.log',
    time: true,
    max_memory_restart: '1G',
    node_args: '--max-old-space-size=1024'
  }]
};
```

### Nginx åå‘ä»£ç†

åˆ›å»º `nginx.conf`ï¼š

```nginx
events {
    worker_connections 1024;
}

http {
    upstream langchain_ai {
        server localhost:3001;
    }

    # HTTP é‡å®šå‘åˆ° HTTPS
    server {
        listen 80;
        server_name yourdomain.com;
        return 301 https://$server_name$request_uri;
    }

    # HTTPS é…ç½®
    server {
        listen 443 ssl http2;
        server_name yourdomain.com;

        # SSL é…ç½®
        ssl_certificate /etc/nginx/ssl/cert.pem;
        ssl_certificate_key /etc/nginx/ssl/key.pem;
        ssl_protocols TLSv1.2 TLSv1.3;
        ssl_ciphers HIGH:!aNULL:!MD5;

        # ä»£ç†é…ç½®
        location / {
            proxy_pass http://langchain_ai;
            proxy_http_version 1.1;
            proxy_set_header Upgrade $http_upgrade;
            proxy_set_header Connection 'upgrade';
            proxy_set_header Host $host;
            proxy_set_header X-Real-IP $remote_addr;
            proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;
            proxy_set_header X-Forwarded-Proto $scheme;
            proxy_cache_bypass $http_upgrade;
        }

        # WebSocket æ”¯æŒ (MCP)
        location /ws {
            proxy_pass http://localhost:8080;
            proxy_http_version 1.1;
            proxy_set_header Upgrade $http_upgrade;
            proxy_set_header Connection "upgrade";
            proxy_set_header Host $host;
            proxy_set_header X-Real-IP $remote_addr;
        }

        # å®‰å…¨å¤´
        add_header X-Content-Type-Options nosniff;
        add_header X-Frame-Options DENY;
        add_header X-XSS-Protection "1; mode=block";
    }
}
```

---

## ğŸ“Š ç›‘æ§å’Œæ—¥å¿—

### åº”ç”¨ç›‘æ§

```javascript
// æ·»åŠ åˆ° index.js
const promBundle = require("express-prom-bundle");

// Prometheus ç›‘æ§
const metricsMiddleware = promBundle({
  includePath: true,
  includeStatusCode: true,
  normalizePath: true,
  promClient: {
    collectDefaultMetrics: {}
  }
});

app.use(metricsMiddleware);
```

### å¥åº·æ£€æŸ¥ç«¯ç‚¹

```javascript
app.get('/health', (req, res) => {
  const health = {
    uptime: process.uptime(),
    message: 'OK',
    timestamp: Date.now(),
    pid: process.pid,
    memory: process.memoryUsage(),
    env: process.env.NODE_ENV
  };
  
  res.status(200).json(health);
});
```

### æ—¥å¿—é…ç½®

```javascript
const winston = require('winston');

const logger = winston.createLogger({
  level: 'info',
  format: winston.format.combine(
    winston.format.timestamp(),
    winston.format.errors({ stack: true }),
    winston.format.json()
  ),
  transports: [
    new winston.transports.File({ filename: 'logs/error.log', level: 'error' }),
    new winston.transports.File({ filename: 'logs/combined.log' }),
    new winston.transports.Console({
      format: winston.format.simple()
    })
  ]
});
```

---

## ğŸ›¡ï¸ å®‰å…¨é…ç½®

### ç¯å¢ƒå˜é‡å®‰å…¨

```bash
# ä½¿ç”¨åŠ å¯†çš„ç¯å¢ƒå˜é‡å­˜å‚¨
# AWS Secrets Manager
aws secretsmanager create-secret \
  --name "langchain-ai/openai-key" \
  --secret-string "your-openai-key"

# Azure Key Vault
az keyvault secret set \
  --vault-name "langchain-vault" \
  --name "openai-key" \
  --value "your-openai-key"
```

### å®‰å…¨ä¸­é—´ä»¶

```javascript
const helmet = require('helmet');
const rateLimit = require('express-rate-limit');

// å®‰å…¨å¤´
app.use(helmet());

// é€Ÿç‡é™åˆ¶
const limiter = rateLimit({
  windowMs: 15 * 60 * 1000, // 15 minutes
  max: 100 // limit each IP to 100 requests per windowMs
});

app.use('/api/', limiter);

// CORS é…ç½®
app.use(cors({
  origin: process.env.ALLOWED_ORIGINS?.split(',') || 'http://localhost:3000',
  credentials: true
}));
```

### SSL/TLS é…ç½®

```bash
# Let's Encrypt è¯ä¹¦
certbot --nginx -d yourdomain.com

# æˆ–ä½¿ç”¨ Cloudflare
# åœ¨ Cloudflare ä¸­é…ç½® SSL/TLS åŠ å¯†æ¨¡å¼ä¸º "Full (strict)"
```

---

## ğŸ” æ•…éšœæ’é™¤

### å¸¸è§é—®é¢˜

#### 1. ç«¯å£å†²çª
```bash
# æ£€æŸ¥ç«¯å£ä½¿ç”¨æƒ…å†µ
netstat -tulpn | grep :3001
netstat -tulpn | grep :8080

# æ€æ­»å ç”¨ç«¯å£çš„è¿›ç¨‹
sudo kill -9 $(lsof -ti:3001)
```

#### 2. å†…å­˜ä¸è¶³
```bash
# ç›‘æ§å†…å­˜ä½¿ç”¨
top -p $(pgrep -f "node.*index.js")

# å¢åŠ  Node.js å†…å­˜é™åˆ¶
node --max-old-space-size=2048 index.js
```

#### 3. MCP è¿æ¥é—®é¢˜
```bash
# æ£€æŸ¥ WebSocket è¿æ¥
curl --include \
     --no-buffer \
     --header "Connection: Upgrade" \
     --header "Upgrade: websocket" \
     --header "Sec-WebSocket-Key: SGVsbG8sIHdvcmxkIQ==" \
     --header "Sec-WebSocket-Version: 13" \
     http://localhost:8080/
```

### æ—¥å¿—åˆ†æ

```bash
# æŸ¥çœ‹é”™è¯¯æ—¥å¿—
tail -f logs/error.log

# æŸ¥çœ‹å®æ—¶æ—¥å¿—
pm2 logs langchain-ai --lines 100

# åˆ†æè®¿é—®æ¨¡å¼
awk '{print $1}' access.log | sort | uniq -c | sort -nr
```

### æ€§èƒ½ä¼˜åŒ–

```javascript
// å¯ç”¨å‹ç¼©
const compression = require('compression');
app.use(compression());

// é™æ€æ–‡ä»¶ç¼“å­˜
app.use(express.static('public', {
  maxAge: '1d',
  etag: false
}));

// è¿æ¥æ± ä¼˜åŒ–
const cluster = require('cluster');
const numCPUs = require('os').cpus().length;

if (cluster.isMaster) {
  for (let i = 0; i < numCPUs; i++) {
    cluster.fork();
  }
} else {
  // å·¥ä½œè¿›ç¨‹è¿è¡Œåº”ç”¨
  app.listen(PORT);
}
```

---

## ğŸ“š éƒ¨ç½²æ¸…å•

### éƒ¨ç½²å‰æ£€æŸ¥

- [ ] ç¯å¢ƒå˜é‡é…ç½®å®Œæˆ
- [ ] ä¾èµ–åŒ…å®‰è£…æˆåŠŸ
- [ ] æ•°æ®åº“è¿æ¥æµ‹è¯•é€šè¿‡
- [ ] SSL è¯ä¹¦é…ç½®æ­£ç¡®
- [ ] é˜²ç«å¢™è§„åˆ™è®¾ç½®
- [ ] ç›‘æ§å’Œæ—¥å¿—é…ç½®
- [ ] å¤‡ä»½ç­–ç•¥åˆ¶å®š

### éƒ¨ç½²åéªŒè¯

- [ ] å¥åº·æ£€æŸ¥é€šè¿‡
- [ ] API æ¥å£æµ‹è¯•
- [ ] MCP åŠŸèƒ½éªŒè¯
- [ ] WebSocket è¿æ¥æ­£å¸¸
- [ ] æ€§èƒ½æŒ‡æ ‡ç›‘æ§
- [ ] é”™è¯¯æ—¥å¿—æ£€æŸ¥
- [ ] å®‰å…¨æ‰«æé€šè¿‡

---

**ğŸ¯ éƒ¨ç½²æˆåŠŸï¼æ‚¨çš„ LangChain AI + MCP åº”ç”¨å·²å‡†å¤‡å¥½æœåŠ¡ç”¨æˆ·ï¼**

å¦‚éœ€æ›´å¤šæ”¯æŒï¼Œè¯·æŸ¥çœ‹ï¼š
- [API æ–‡æ¡£](API_DOCUMENTATION.md)
- [MCP æŒ‡å—](MCP_GUIDE.md)
- [æ•…éšœæ’é™¤æ–‡æ¡£](TROUBLESHOOTING.md)